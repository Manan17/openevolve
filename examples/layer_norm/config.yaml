# OpenEvolve Default Configuration
# This file contains all available configuration options with sensible defaults
# You can use this as a template for your own configuration

# General settings
max_iterations: 200                  # Maximum number of evolution iterations
checkpoint_interval: 10               # Save checkpoints every N iterations
log_level: "INFO"                     # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
log_dir: null                         # Custom directory for logs (default: output_dir/logs)
random_seed: 42                       # Random seed for reproducibility (null = random, 42 = default)

# Evolution settings
diff_based_evolution: true            # Use diff-based evolution (true) or full rewrites (false)
max_code_length: 20000                # Maximum allowed code length in characters

# LLM configuration
llm:
  api_base: "http://localhost:8000/v1"
  api_key: null
  models:
    - name: "Qwen/Qwen3-4B"
      weight: 1.0
  evaluator_models:
    - name: "Qwen/Qwen3-4B"
      weight: 1.0
  temperature: 0.8
  top_p: 0.8
  max_tokens: 3000

  # Request parameters
  timeout: 7000                         # Timeout for API requests in seconds
  retries: 3                          # Number of retries for failed requests
  retry_delay: 5                      # Delay between retries in seconds

# Prompt configuration
prompt:
  template_dir: null                  # Custom directory for prompt templates
  system_message: "You are an expert Triton kernel optimization specialist. Your task is to improve the performance of a Layer Norm kernel implemented in Triton. Focus on optimizing both forward and backward passes by improving memory access patterns, block sizes, and computation efficiency while maintaining numerical accuracy. Don't be a fool and try to go deep in a solution that is going towards a wrong direction, if you feel so, try to change your approach. Our goal is to save memory and increase speed so that we can have a good mankind ahead, now the future is in your hands."
  evaluator_system_message: "You are an expert code reviewer."

  # Number of examples to include in the prompt
  num_top_programs: 3                 # Number of top-performing programs to include
  num_diverse_programs: 2             # Number of diverse programs to include

  # Template stochasticity
  use_template_stochasticity: true    # Use random variations in templates for diversity
  template_variations:                # Different phrasings for parts of the template
    improvement_suggestion:
      - "Here's how we could improve this code:"
      - "I suggest the following improvements:"
      - "We can enhance this code by:"

  # Note: meta-prompting features are not yet implemented

# Database configuration
database:
  # General settings
  db_path: null                       # Path to persist database (null = in-memory only)
  in_memory: true                     # Keep database in memory for faster access
  log_prompts: true                  # If true, log all prompts and responses into the database

  # Evolutionary parameters
  population_size: 1000               # Maximum number of programs to keep in memory
  archive_size: 100                   # Size of elite archive
  num_islands: 5                      # Number of islands for island model (separate populations)

  # Island-based evolution parameters
  # Islands provide diversity by maintaining separate populations that evolve independently.
  # Migration periodically shares the best solutions between adjacent islands.
  migration_interval: 50              # Migrate between islands every N generations
  migration_rate: 0.1                 # Fraction of top programs to migrate (0.1 = 10%)

  # Selection parameters
  elite_selection_ratio: 0.1          # Ratio of elite programs to select
  exploration_ratio: 0.2              # Ratio of exploration vs exploitation
  exploitation_ratio: 0.7             # Ratio of exploitation vs random selection
  # Note: diversity_metric is fixed to "edit_distance" (feature_based not implemented)

  # Feature map dimensions for MAP-Elites
  # Default if not specified: ["complexity", "diversity"]
  # 
  # Built-in features (always available, computed by OpenEvolve):
  #   - "complexity": Code length
  #   - "diversity": Code structure diversity
  #
  # You can mix built-in features with custom metrics from your evaluator:
  feature_dimensions:                 # Dimensions for MAP-Elites feature map
    - "complexity"                    # Code length (built-in)
    - "diversity"                     # Code diversity (built-in)
  # Example with custom features:
  # feature_dimensions:
  #   - "performance"                 # Must be returned by your evaluator
  #   - "correctness"                 # Must be returned by your evaluator
  #   - "memory_efficiency"           # Must be returned by your evaluator
  
  # Number of bins per dimension
  # Can be a single integer (same for all dimensions) or a dict
  feature_bins: 10                    # Number of bins per dimension
  # Example of per-dimension configuration:
  # feature_bins:
  #   complexity: 10                  # 10 bins for complexity
  #   diversity: 15                   # 15 bins for diversity
  #   performance: 20                 # 20 bins for custom metric
  
  diversity_reference_size: 20        # Size of reference set for diversity calculation

# Evaluator configuration
evaluator:
  # General settings
  timeout: 300                        # Maximum evaluation time in seconds
  max_retries: 3                      # Maximum number of retries for evaluation

  # Note: resource limits (memory_limit_mb, cpu_limit) are not yet implemented

  # Evaluation strategies
  cascade_evaluation: true            # Use cascade evaluation to filter bad solutions early
  cascade_thresholds:                 # Thresholds for advancing to next evaluation stage
    - 0.5                             # First stage threshold
    - 0.75                            # Second stage threshold
    - 0.9                             # Third stage threshold

  # Parallel evaluation
  parallel_evaluations: 4             # Number of parallel evaluations
  # Note: distributed evaluation is not yet implemented

  # LLM-based feedback (experimental)
  use_llm_feedback: false             # Use LLM to evaluate code quality
  llm_feedback_weight: 0.1            # Weight for LLM feedback in final score
